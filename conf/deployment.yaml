build:
  no_build: true

custom:
  basic-cluster-props: &basic-cluster-props
    spark_version: "12.2.x-cpu-ml-scala2.12"
    node_type_id: "m5d.large"

  basic-static-cluster: &basic-static-cluster
    new_cluster:
      <<: *basic-cluster-props
      num_workers: 2

  dev-cluster-spec: &dev-cluster-spec
    spark_version: "12.2.x-cpu-ml-scala2.12"
    num_workers: 1
    node_type_id: "m5d.large"
  
  dev-cluster-config: &dev-cluster-config
    new_cluster:
      << *dev-cluster-spec

environments:
  default:
    workflows:
    - name: "dbx-wheel-example"
      tags: 
        env: "development"
        team: "data-eng"

      job_clusters:
      - job_cluster_key: "basic-cluster"
        <<: *basic-static-cluster

      tasks:
      - task_key: "your-task-01"
        job_cluster_key: "basic-cluster"
        max_retries: 0
        python_wheel_task:
          package_name: "sparkpi"
          entry_point: "run"
        libraries:
        - whl: "file://dist/sparkpi-0.1.0-py3-none-any.whl"
        instance-profile: instance-profile://one-env-databricks-access


          